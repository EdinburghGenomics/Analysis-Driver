__author__ = 'mwham'
import glob
import shutil
import os.path
import hashlib
from analysis_driver import writer
from analysis_driver.app_logging import get_logger
from analysis_driver.executor import StreamExecutor
from analysis_driver.config import default as cfg

app_logger = get_logger('util')


def bcbio_prepare_samples(job_dir, sample_id, id_fastqs):
    # setup the BCBio merged csv file
    bcbio_csv_file = writer.write_bcbio_csv(job_dir, sample_id, id_fastqs)
    app_logger.info('Setting up BCBio samples from ' + bcbio_csv_file)

    merged_dir = os.path.join(job_dir, 'merged')
    return_code = _localexecute(
        os.path.join(cfg['bcbio'], 'bin', 'bcbio_prepare_samples.py'),
        '--out',
        merged_dir,
        '--csv',
        bcbio_csv_file
    )
    # find the merged fastq files
    new_fastq_files = glob.glob(os.path.join(merged_dir, sample_id + '_R?.fastq.gz'))
    if new_fastq_files and return_code == 0:
        return new_fastq_files


def setup_bcbio_run(template, csv_file, run_dir, *fastqs):
    """
    Call localexecute to run 'bcbio -w template' on relevant input files.
    :param str bcbio: Path to the bcbio_nextgen.py executable
    :param str template: Path to the yaml file to use as the run template.
    :param str csv_file: Path to the csv sample file as generated by BCBioCSVWriter
    :param str run_dir: Path to the run folder
    :param str fastqs: Full paths to each input fastq file
    """
    app_logger.info('Setting up BCBio run')
    _localexecute(
        os.path.join(cfg['bcbio'], 'bin', 'bcbio_nextgen.py'),
        '-w',
        'template',
        template,
        run_dir,
        csv_file,
        *fastqs
    )


def transfer_output_files(sample_id, output_dir, source_path_mapping):
    """
    :param str sample_id: a sample id, acting as the basename for the file
    :param str output_dir: where to send the output file
    :param dict source_path_mapping: a mapping describing where to find each type of output file
    :return: 0 if successful, 1 if expected file not found
    """
    exit_status = 0
    for f in cfg['output_files']:
        app_logger.debug('Transferring ' + str(f))
        source_dir = source_path_mapping[f['type']]  # f['type'] = 'vcf'; source_dir = bcbio_source_dir
        base_name = f['name'].replace('*', sample_id)  # '*.vcf.gz' -> sample_id.vcf.gz
        source_file = os.path.join(source_dir, base_name)  # bcbio_source_dir/sample_id.vcf.gz
        rename_to = f.get('rename_to')  # '.g.vcf.gz'
        if rename_to:
            base_name = base_name.replace(f['name'][1:], rename_to)  # sample_id.vcf.gz -> sample_id.g.vcf.gz

        output_file = os.path.join(output_dir, base_name)  # output_dir/sample_id.g.vcf.gz
        app_logger.info('Looking for file: ' + source_file)

        if os.path.isfile(source_file):
            app_logger.info('Found file. Copying to ' + output_file + '.')
            shutil.copyfile(
                source_file,
                output_file
            )
            app_logger.debug('Generating md5 checksum')
            md5 = hashlib.md5()
            with open(output_file, 'rb') as g:
                chunk = g.read(8192)
                while chunk:
                    md5.update(chunk)
                    chunk = g.read(8192)

            with open(output_file + '.md5', 'w') as h:
                h.write(md5.hexdigest())
            app_logger.info('Done')

        else:
            app_logger.info('Expected output file not found: ' + source_file)
            exit_status += 1

    return exit_status


def _localexecute(*args):
    executor = StreamExecutor(list(args))
    executor.start()
    return_code = executor.join()
    app_logger.info('Exit status: ' + str(return_code))
    return return_code
